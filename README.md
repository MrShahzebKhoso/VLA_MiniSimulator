# ğŸ§  Visionâ€‘Languageâ€‘Action (VLA) Mini Simulator

A simple, Colabâ€‘ready **Visionâ€‘Languageâ€‘Action (VLA)** technical demo showing how vision, language and action can be integrated â€” suitable for portfolio and developer showcase use.

## ğŸ¯ Objective

> â€œKeep the pole balanced.â€

In this demo youâ€™ll find two notebooks:

- `VLA_Conceptual_Demo.ipynb` â€” A conceptual demo using an image + instruction â†’ action mapping via CLIP embeddings and a small action head.  
- `VLA_Practical_Demo.ipynb` â€” A practical demo that uses the CartPoleâ€‘v1 environment to show how an agent could interpret visual state + language instruction â†’ control action.

## âš™ï¸ Setup & Usage

Run easily in Google Colab:

1. Open one of the notebooks in Colab.  
2. Run all cells sequentially.  
3. If using the practical demo, it will log the agent steps and generate a `.mp4` video of the simulation.

## ğŸ§© Project Structure

```
VLA_MiniSimulator/
â”‚
â”œâ”€â”€ VLA_Conceptual_Demo.ipynb     # Conceptual VLA pipeline
â”œâ”€â”€ VLA_Practical_Demo.ipynb      # Embodied simulation demo
â””â”€â”€ README.md                     # This file
```

## ğŸ§ª Example Output

### Logs
```
ğŸ¯ Instruction: "Keep the pole balanced"

ğŸŒ€ Step 0
Observation: [ 0.0208809 -0.1810137 -0.0358661  0.2689328 ]
Action taken: 0
Reward received: 1.000
------------------------------------------------------------
```

### Video
The practical demo produces a movie (`.mp4`) showing the agent balancing the pole, which can be embedded or reviewed as part of the demonstration.

## ğŸ“„ Features

- âœ… Visionâ€‘language reasoning with a CLIPâ€‘style image+text embedding.  
- âœ… Structured log output of action decisions and rewards.  
- âœ… Generated video of simulation to visualize results.  
- âœ… Fully runnable in Colab without heavy dependencies.


---
